{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CD8kTnfZyzmW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LandUseDataset(Dataset):\n",
        "    def __init__(self, csv_file=None, image_dir=None, transform=None, dataframe=None):\n",
        "        if dataframe is not None:\n",
        "            self.data = dataframe.reset_index(drop=True)\n",
        "        elif csv_file is not None:\n",
        "            self.data = pd.read_csv(csv_file)\n",
        "        else:\n",
        "            raise ValueError(\"Entweder 'csv_file' oder 'dataframe' muss übergeben werden.\")\n",
        "\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.classes = sorted(self.data['class'].unique())\n",
        "        self.class_to_idx = {label: idx for idx, label in enumerate(self.classes)}\n",
        "        self.idx_to_class = {idx: label for label, idx in self.class_to_idx.items()}\n",
        "        self.data['label_idx'] = self.data['class'].map(self.class_to_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.image_dir, row['fn'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = row['label_idx']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "txAxdJzyzyuG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "VMrdIHReBJLq"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path_train = '/content/drive/MyDrive/Hackerthon2/train.zip'\n",
        "extract_path_train = '/content/imagesFinal/train'\n",
        "\n",
        "with zipfile.ZipFile(zip_path_train, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path_train)\n"
      ],
      "metadata": {
        "id": "EC1A7HrlBPf6"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path_test = '/content/drive/My Drive/Hackerthon2/test.zip'\n",
        "extract_path_test = '/content/imagesFinal/test'\n",
        "\n",
        "with zipfile.ZipFile(zip_path_test, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path_test)\n"
      ],
      "metadata": {
        "id": "KJ3NVkUHBnRd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train-Dateien:\", os.listdir(extract_path_train)[:5])\n",
        "print(\"Test-Dateien:\", os.listdir(extract_path_test)[:5])\n",
        "\n",
        "train_dir = '/content/imagesFinal/train/train'\n",
        "test_dir = '/content/imagesFinal/test/test'\n",
        "\n",
        "train_files = [f for f in os.listdir(train_dir) if os.path.isfile(os.path.join(train_dir, f))]\n",
        "test_files = [f for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))]\n",
        "\n",
        "print(f\"Train-Bilder: {len(train_files)}\")\n",
        "print(f\"Test-Bilder: {len(test_files)}\")\n"
      ],
      "metadata": {
        "id": "vc0I-x_5B8kq"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/train.csv')\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "TuIsX-7R17EV"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "csv_path = '/content/train.csv'\n",
        "image_dir = '/content/imagesFinal/train/train'\n",
        "\n",
        "train_dataset = LandUseDataset(\n",
        "    csv_file=csv_path,\n",
        "    image_dir=image_dir,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "oFoG3m5Iy532"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "\n",
        "model = resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "1PI9d2J_y-kH"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "U8FeCMrby_Oz"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/train.csv')\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "DnBsEOlx2Y7A"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n"
      ],
      "metadata": {
        "id": "l7HgMh7czBRl"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_filenames = sorted([\n",
        "            f for f in os.listdir(image_dir)\n",
        "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "        ])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_filenames[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_name\n"
      ],
      "metadata": {
        "id": "fE-_KW_B7c_O"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = '/content/images/test/test'\n",
        "test_dataset = TestDataset(image_dir=test_dir, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(\"Anzahl Testbilder:\", len(test_dataset))\n",
        "print(\"Bildnamen:\", test_dataset.image_filenames[:5])\n"
      ],
      "metadata": {
        "id": "g2i9e-ds731s"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('/content/train.csv')\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['class'], random_state=42)\n"
      ],
      "metadata": {
        "id": "NrLC0wtE8r8p"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = LandUseDataset(\n",
        "    dataframe=train_df,\n",
        "    image_dir='/content/images/train/train',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "val_dataset = LandUseDataset(\n",
        "    dataframe=val_df,\n",
        "    image_dir='/content/images/train',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "pbh14C3S8x4P"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_df))\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "id": "6H7fT_ln9J-N"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, class_names):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = correct / total\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    return predictions, true_labels\n"
      ],
      "metadata": {
        "id": "WZnBHDi89Od9"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds, true = evaluate(model, val_loader, class_names=train_dataset.classes)\n"
      ],
      "metadata": {
        "id": "Dwnv7yx59StT"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "filenames = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, img_names in test_loader:\n",
        "        inputs = inputs.to('cuda')\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        filenames.extend(img_names)\n",
        "\n",
        "label_names = [train_dataset.idx_to_class[p] for p in predictions]\n",
        "\n",
        "submission = pd.DataFrame({'fn': filenames, 'class': label_names})\n",
        "submission = submission.sort_values('fn').reset_index(drop=True)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('submission.csv')\n"
      ],
      "metadata": {
        "id": "1uB3wtXHzFPM"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "test_dir = '/content/images/test/test'\n",
        "files = os.listdir(test_dir)\n",
        "\n",
        "print(\"Anzahl Einträge im Testordner:\", len(files))\n",
        "print(\"Beispiel-Dateien:\", files[:5])\n"
      ],
      "metadata": {
        "id": "VPBpAlcMHb0M"
      },
      "execution_count": 81,
      "outputs": []
    }
  ]
}
